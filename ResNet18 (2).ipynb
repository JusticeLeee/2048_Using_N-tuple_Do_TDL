{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-assistant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-jacksonville",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-strike",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getData(mode):\n",
    "    if mode == 'train':\n",
    "        img = pd.read_csv('train_img.csv')\n",
    "        label = pd.read_csv('train_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)\n",
    "    else:\n",
    "        img = pd.read_csv('test_img.csv')\n",
    "        label = pd.read_csv('test_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-casino",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RetinopathyLoader(data.Dataset):\n",
    "    def __init__(self, root, mode):\n",
    "    \n",
    "        self.root = root\n",
    "        # the type is numpy.ndarray\n",
    "        self.img_name, self.label = getData(mode)\n",
    "        self.mode = mode\n",
    "        print(\"> Found %d images...\" % (len(self.img_name)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #get the path and load the img \n",
    "        path = self.root + self.img_name[index] + '.jpeg' \n",
    "#         img  = mpimg.imread(path)\n",
    "        img  = Image.open(path).convert('RGB')\n",
    "\n",
    "        #get label according to indx\n",
    "        label = self.label[index]\n",
    "        \n",
    "        #set the trasnform\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5)\n",
    "        ])\n",
    "        \n",
    "        # Use transform make \n",
    "        img = transform(img)\n",
    "        # make the size 3*512*512 -> 1*3*512*512\n",
    "#         img = torch.unsqueeze(img, 0)\n",
    "        # get the tensor form label\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "\n",
    "#         img = transforms.Normalize(img,(0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         img = torchvision.transforms.ToPILImage(img)\n",
    "#         img = torchvision.transforms.ToTensor()(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "train_data = RetinopathyLoader(\"data/\", \"train\")\n",
    "test_data  = RetinopathyLoader(\"data/\", \"test\")\n",
    "\n",
    "train_data = DataLoader(train_data,batch_size=4)\n",
    "test_data = DataLoader(test_data,batch_size=4)\n",
    "\n",
    "# print(train_data[0][0].shape)\n",
    "# transform = transforms.Compose([transforms.ToPILImage()])\n",
    "# transforms.ToPILImage()(train_data[0][0][0]).show()\n",
    "# transform(train_data[0][0][0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-comparison",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for data in (train_data):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-dining",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-continent",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# redefine ResNet by spec\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        # maxpool follow spec.\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "#         self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        self.linear = nn.Linear(in_features=51200, out_features=5, bias=True)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # maxpool\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = F.avg_pool2d(out, 4)\n",
    "        out = F.avg_pool2d(out, kernel_size=7, stride=1, padding=0)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-indonesia",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def ResNet18_train(net):\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    for idx,pair in enumerate(train_data):\n",
    "        net.train()\n",
    "        inputs,labels = pair\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        # make gradients be zero , default is accumulated \n",
    "        optimizer.zero_grad()\n",
    "        #put the input to net , output size 1*1000 \n",
    "        outputs = net(inputs)\n",
    "\n",
    "        #caclulate lose\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print(loss.item())\n",
    "        #caculate gradient\n",
    "        loss.backward()\n",
    "        #using gradient update weight\n",
    "        optimizer.step()\n",
    "        #weight decay\n",
    "        scheduler.step()\n",
    "        for i in range(len(labels)):\n",
    "            ground_true = labels[i].item()\n",
    "            pred_y = torch.argmax(outputs[i]).item()\n",
    "    #         print(\"pred= \",pred_y)\n",
    "            confusion_yTrue.append(ground_true)\n",
    "            confusion_yPred.append(pred_y)\n",
    "        \n",
    "            if ground_true == pred_y:\n",
    "                true_ans = true_ans + 1\n",
    "            else:\n",
    "                false_ans = false_ans + 1\n",
    "                \n",
    "        if(idx!=0 and idx%100==0):\n",
    "            print(\"idx = \",idx,\"Train_accuracy = \",true_ans/(false_ans+true_ans))\n",
    "    return true_ans, false_ans, confusion_yTrue, confusion_yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-brunei",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evalutation(net):\n",
    "    net.eval()\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    for idx,pair in enumerate(test_data):\n",
    "        inputs,labels = pair\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            ground_true = labels[i].item()\n",
    "            pred_y = torch.argmax(outputs[i]).item()\n",
    "    #         print(\"pred= \",pred_y)\n",
    "            confusion_yTrue.append(ground_true)\n",
    "            confusion_yPred.append(pred_y)\n",
    "            if ground_true == pred_y:\n",
    "                true_ans = true_ans + 1\n",
    "            else:\n",
    "                false_ans = false_ans + 1\n",
    "                \n",
    "        if(idx!=0 and idx%100==0):\n",
    "            print(\"idx = \",idx,\"Eval_accuracy = \",true_ans/(false_ans+true_ans))\n",
    "            \n",
    "    return true_ans, false_ans, confusion_yTrue, confusion_yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-teens",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validation(net,path):\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    net.eval()\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    for idx,pair in enumerate(train_data):\n",
    "        inputs,labels = pair\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.long().to(device)\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            ground_true = labels[i].item()\n",
    "            pred_y = torch.argmax(outputs[i]).item()\n",
    "    #         print(\"pred= \",pred_y)\n",
    "            confusion_yTrue.append(ground_true)\n",
    "            confusion_yPred.append(pred_y)\n",
    "            if ground_true == pred_y:\n",
    "                true_ans = true_ans + 1\n",
    "            else:\n",
    "                false_ans = false_ans + 1\n",
    "            \n",
    "    return true_ans/(false_ans+true_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-indie",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training\n",
    "flag =\"\"\n",
    "def run(net,n=10):\n",
    "    global flag\n",
    "    if(net==pre_net):\n",
    "        print(\"pretrain network:\")\n",
    "        flag =\"pre\"\n",
    "    else:\n",
    "        print(\"newtrain network:\")\n",
    "        flag =\"new\"\n",
    "    train_epoch_list = []\n",
    "    train_acc_list = []\n",
    "    test_epoch_list = []\n",
    "    test_acc_list = []\n",
    "    f= open('ResNet18.txt','a')\n",
    "    for epoch in range(10):\n",
    "        print (\"Train: epoch \"+ str(epoch+1))\n",
    "        start = time.time()\n",
    "\n",
    "        #Traning\n",
    "        net.train()\n",
    "        train_epoch_list.append(epoch)\n",
    "#         result = ResNet18_train(net,len(train_data))\n",
    "        result = ResNet18_train(net)\n",
    "        train_y_true = result[2]\n",
    "        train_y_pred = result[3]\n",
    "        ACC = (result[0]/(result[0]+result[1]))\n",
    "        train_acc_list.append(ACC)\n",
    "        f.write(str(ACC)+\" \")\n",
    "        print (\"TrainAccuracy is : \"+str(ACC))\n",
    "\n",
    "        \n",
    "        #Testing\n",
    "        net.eval()\n",
    "        test_epoch_list.append(epoch)\n",
    "#         result = evalutation(net,test_data,len(test_data))\n",
    "        result = evalutation(net)\n",
    "        test_y_true = result[2]\n",
    "        test_y_pred = result[3]\n",
    "        ACC = (result[0]/(result[0]+result[1]))\n",
    "        test_acc_list.append(ACC)\n",
    "        f.write(str(ACC)+\"\\n\")\n",
    "        print (\"TestAccuracy is : \"+str(ACC))\n",
    "        end = time.time()\n",
    "        print(\"執行時間：%f 秒\" % (end - start))\n",
    "        if(ACC==max(test_acc_list)):\n",
    "            torch.save(net.state_dict(), \"CKPT/\"+flag+\"_ResNet18_final_ckpt\")\n",
    "    return train_y_true,train_y_pred,test_y_true,test_y_pred,train_acc_list,test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "def plot_confusion_matrix(y_true,y_pred,title):\n",
    "    print(title+\":\")\n",
    "    cm = confusion_matrix(y_true,y_true,labels=[0,1,2,3,4])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1,2,3,4])\n",
    "    disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotImg():\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.plot(new_tran_accu,color=\"blue\",label=\"new_tran_accu\")\n",
    "    plt.plot(new_test_accu,color=\"orange\",label=\"new_test_accu\")\n",
    "    plt.plot(pretrain_tran_accu,color=\"green\",label=\"pretrain_tran_accu\")\n",
    "    plt.plot(pretrain_test_accu,color=\"red\",label=\"pretrain_test_accu\")\n",
    "    plt.title(\"ResNet18\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-consolidation",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "load=0\n",
    "from models import Pre_ResNet\n",
    "pre_net = Pre_ResNet().to(device)\n",
    "net = ResNet18().to(device)\n",
    "\n",
    "if(load==0):\n",
    "    #pretrain net\n",
    "    criterion = F.cross_entropy\n",
    "    optimizer = torch.optim.SGD(pre_net.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer,gamma=5e-4) # weight decay\n",
    "    result_old = run(pre_net)\n",
    "    confusion_matrix(result_old[0],result_old[1],labels=[0,1,2,3,4])\n",
    "    plot_confusion_matrix(result_old[0],result_old[0],title=\"pretrain_train_confusion\")\n",
    "    plot_confusion_matrix(result_old[2],result_old[3],title=\"pretrain_test_confusion\")\n",
    "    pretrain_tran_accu = result_old[4]\n",
    "    pretrain_test_accu = result_old[5]\n",
    "\n",
    "    #new net\n",
    "    criterion = F.cross_entropy\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer,gamma=5e-4) # weight decay\n",
    "    result_new = run(net)\n",
    "    plot_confusion_matrix(result_new[0],result_new[1],title=\"new_train_confusion\")\n",
    "    plot_confusion_matrix(result_new[2],result_new[3],title=\"new_test_confusion\")\n",
    "    new_tran_accu = result_new[4]\n",
    "    new_test_accu = result_new[5]\n",
    "\n",
    "else:\n",
    "    path = \"CKPT/pre_ResNet18_final_ckpt\"\n",
    "    print(validation(pre_net,test_data,len(test_data),path))\n",
    "    path = \"CKPT/new_ResNet18_final_ckpt\"\n",
    "    print(validation(net,test_data,len(test_data),path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-parker",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# need to set load = 0\n",
    "plotImg()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
